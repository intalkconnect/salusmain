require("dotenv").config();
const { Worker } = require("bullmq");
const fs = require("fs");
const path = require("path");
const { supabase } = require("../src/utils/supabaseClient");
const { normalizeText, limparTituloMedico } = require("../src/utils/textParser");
const { callOpenAIWithVision, callOpenAIWithText } = require("../src/utils/openaiHelper");
const { extractTextFromPDF, isManuscriptImage } = require("../src/utils/fileUtils");
const { log, error } = require("../src/utils/logger");

// üîó Configura√ß√£o da conex√£o Redis
const connection = {
  connection: {
    url: process.env.REDIS_URL,
  },
};

console.log("üöÄ Worker process_job iniciado e aguardando jobs...");

// üöÄ Worker process_job
const worker = new Worker(
  "process_job",
  async (job) => {
    const { filepath, ext, filename, jobId, clientId, openaiKey } = job.data;
    const startedAt = new Date();

    try {
      log(`üì• Processando job ${jobId}`);
      log(`üóÇÔ∏è Dados do job: ${JSON.stringify(job.data, null, 2)}`);

      // üõë Verifica√ß√£o de filepath
      if (!filepath) {
        throw new Error(`‚ùå Filepath ausente no job ${jobId}`);
      }

      if (!fs.existsSync(filepath)) {
        throw new Error(`‚ùå Arquivo n√£o encontrado em ${filepath} para job ${jobId}`);
      }

      // üîÑ Atualiza status para processing
      await logJobMetric(clientId, jobId, ext, "processing", null, startedAt, null);

      const extClean = path.extname(filepath).toLowerCase();
      let result;

      if ([".jpg", ".jpeg", ".png"].includes(extClean)) {
        const isManuscript = await isManuscriptImage(filepath);
        if (isManuscript) {
          await logJobMetric(clientId, jobId, ext, "human", "manuscrito identificado", startedAt, new Date());
          log(`üë§ Job ${jobId} marcado como HUMAN ‚Äî manuscrito identificado`);
          return;
        }

        log("üß† Enviando imagem para OpenAI Vision...");
        result = await callOpenAIWithVision(filepath, openaiKey, jobId);
      } else if (extClean === ".pdf") {
        log("üìÑ Extraindo texto de PDF...");
        const { text } = await extractTextFromPDF(filepath);

        if (!text || text.trim().length < 30) {
          await logJobMetric(clientId, jobId, ext, "human", "PDF com pouco texto ou ileg√≠vel", startedAt, new Date());
          log(`üë§ Job ${jobId} marcado como HUMAN ‚Äî PDF ileg√≠vel`);
          return;
        }

        log("üß† Enviando texto de PDF para OpenAI...");
        result = await callOpenAIWithText(text, openaiKey, jobId);
      } else {
        throw new Error(`‚ùå Formato de arquivo n√£o suportado: ${extClean}`);
      }

      if (result.status === "human") {
        await logJobMetric(clientId, jobId, ext, "human", "manuscrito ou ileg√≠vel", startedAt, new Date());
        log(`üë§ Job ${jobId} marcado como HUMAN ‚Äî revis√£o manual necess√°ria`);
        return;
      }

      log("‚úÖ Resultado da IA recebido com sucesso!");

      const patient = normalizeText(result.patient || "");
      const doctor = limparTituloMedico(result.doctor || "");
      const medications = result.medications || {};

      for (const [formulaName, details] of Object.entries(medications)) {
        const { raw_materials = [], form = "", type = "", posology = "", quantity } = details;

        for (const mp of raw_materials) {
          const activeRaw = normalizeText(mp.active || "");
          const dose = parseFloat(mp.dose) || null;
          const unity = mp.unity;

          await supabase.from("recipe_lines").insert({
            filename,
            job_id: jobId,
            text_block: `${formulaName} - ${activeRaw} ${dose}${unity} ${form}`,
            classification: "formula",
            active: activeRaw,
            dose,
            unity,
            form: normalizeText(form),
            type: normalizeText(type),
            posology: normalizeText(posology),
            quantity,
            patient,
            doctor,
            client_id: clientId,
            processed: true,
            reviewed: false,
            created_at: new Date().toISOString(),
          });
        }
      }

      await logJobMetric(clientId, jobId, ext, "sucesso", null, startedAt, new Date());
      log(`üéâ Job ${jobId} conclu√≠do com sucesso!`);

    } catch (err) {
      error(`‚ùå Erro no job ${jobId}: ${err.message}`);
      await logJobMetric(clientId, jobId, ext, "falha", err.message?.slice(0, 200), startedAt, new Date());
    }
  },
  connection
);

// üî• Eventos do worker
worker.on('completed', (job) => {
  console.log(`‚úÖ Job ${job.id} finalizado com sucesso`);
});

worker.on('failed', (job, err) => {
  console.error(`‚ùå Job ${job.id} falhou: ${err.message}`);
});

worker.on('error', (err) => {
  console.error('‚ùå Erro geral no worker:', err);
});

// üìù Fun√ß√£o de log de job
async function logJobMetric(clientId, jobId, fileType, status, errorType = null, startedAt = null, endedAt = null) {
  const { data: existing, error: fetchError } = await supabase
    .from("job_metrics")
    .select("id")
    .eq("job_id", jobId)
    .maybeSingle();

  if (fetchError) {
    error("‚ùå Erro ao buscar job_metrics:", fetchError);
    return;
  }

  if (existing) {
    const { error: updateError } = await supabase
      .from("job_metrics")
      .update({
        status,
        error_type: errorType,
        ended_at: endedAt,
      })
      .eq("job_id", jobId);

    if (updateError) {
      error("‚ùå Erro ao atualizar job_metrics:", updateError);
    }
  } else {
    const { error: insertError } = await supabase.from("job_metrics").insert({
      client_id: clientId,
      job_id: jobId,
      file_type: fileType,
      status,
      error_type: errorType,
      started_at: startedAt,
      ended_at: endedAt,
      created_at: new Date().toISOString(),
    });

    if (insertError) {
      error("‚ùå Erro ao inserir em job_metrics:", insertError);
    }
  }
}

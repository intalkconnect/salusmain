require("dotenv").config();
const { Worker } = require("bullmq");
const { PutObjectCommand } = require('@aws-sdk/client-s3');
const { s3 } = require("../src/utils/minioClient");
const { supabase } = require("../src/utils/supabaseClient");
const { normalizeText, limparTituloMedico } = require("../src/utils/textParser");
const { callOpenAIWithVision, callOpenAIWithText } = require("../src/utils/openaiHelper");
const { extractTextFromPDF, isManuscriptImage } = require("../src/utils/fileUtils");
const { log, error } = require("../src/utils/logger");
const path = require("path");
const fs = require("fs");

const connection = {
  connection: {
    url: process.env.REDIS_URL,
  },
};

const BUCKET_NAME = process.env.MINIO_BUCKET;
const openaiKey = process.env.OPENAI_API_KEY

const worker = new Worker(
  "process_job",
  async (job) => {
    const { filepath, ext, filename, jobId, clientId } = job.data;
    const startedAt = new Date();
    const tempFilePath = filepath;

    const extClean = (ext || path.extname(filepath).replace(".", "").toLowerCase());

    try {
      log(`ðŸ“¥ Processando job ${jobId}`);

      if (!fs.existsSync(tempFilePath)) {
        throw new Error(`Arquivo nÃ£o encontrado em ${tempFilePath}`);
      }

      await logJobMetric(clientId, jobId, ext, "processing", null, startedAt, null);

      const extClean = ext || path.extname(tempFilePath).replace(".", "").toLowerCase();
      let result;

      if (["jpg", "jpeg", "png"].includes(extClean)) {
        const isManuscript = await isManuscriptImage(tempFilePath);
        if (isManuscript) {
          await logJobMetric(clientId, jobId, ext, "human", "manuscrito identificado", startedAt, new Date());
          log(`ðŸ‘¤ Job ${jobId} marcado como HUMAN â€” manuscrito identificado`);
          return;
        }

        log("ðŸ§  Enviando imagem para OpenAI Vision...");
        result = await callOpenAIWithVision(tempFilePath, openaiKey, jobId);
      } else if (extClean === "pdf") {
        log("ðŸ“„ Extraindo texto de PDF...");
        const { text } = await extractTextFromPDF(tempFilePath);
        if (!text || text.trim().length < 30) {
          await logJobMetric(clientId, jobId, ext, "human", "PDF com pouco texto ou ilegÃ­vel", startedAt, new Date());
          log(`ðŸ‘¤ Job ${jobId} marcado como HUMAN â€” PDF ilegÃ­vel`);
          return;
        }
        log("ðŸ§  Enviando texto de PDF para OpenAI...");
        result = await callOpenAIWithText(text, openaiKey, jobId);
      } else {
        throw new Error(`Formato de arquivo nÃ£o suportado: ${extClean}`);
      }

      if (result.status === "human") {
        await logJobMetric(clientId, jobId, ext, "human", "manuscrito ou ilegÃ­vel", startedAt, new Date());
        log(`ðŸ‘¤ Job ${jobId} marcado como HUMAN â€” revisÃ£o manual necessÃ¡ria`);
        return;
      }

      log("âœ… Resultado da IA recebido");

      const patient = normalizeText(result.patient || "");
      const doctor = limparTituloMedico(result.doctor || "");
      const medications = result.medications || {};

      for (const [formulaName, details] of Object.entries(medications)) {
        const {
          raw_materials = [],
          form = "",
          type = "",
          posology = "",
          quantity,
        } = details;

        for (const mp of raw_materials) {
          const activeRaw = normalizeText(mp.active || "");
          const dose = parseFloat(mp.dose) || null;
          const unity = mp.unity;

          await supabase.from("recipe_lines").insert({
            filename,
            job_id: jobId,
            text_block: `${formulaName} - ${activeRaw} ${dose}${unity} ${form}`,
            classification: "formula",
            active: activeRaw,
            dose,
            unity,
            form: normalizeText(form),
            type: normalizeText(type),
            posology: normalizeText(posology),
            quantity,
            patient,
            doctor,
            client_id: clientId,
            processed: true,
            reviewed: false,
            created_at: new Date().toISOString(),
          });
        }
      }

      await logJobMetric(clientId, jobId, ext, "sucesso", null, startedAt, new Date());
      log(`âœ… Job ${jobId} concluÃ­do com sucesso`);
    } catch (err) {
      error(`âŒ Erro no job ${jobId}:`, err);
      await logJobMetric(clientId, jobId, ext, "falha", err.message?.slice(0, 200), startedAt, new Date());
    } finally {
      // ðŸ”¥ Upload para MinIO
      try {
        const fileData = fs.readFileSync(tempFilePath);
        const contentType = {
          pdf: "application/pdf",
          jpg: "image/jpeg",
          jpeg: "image/jpeg",
          png: "image/png",
        }[extClean] || "application/octet-stream";

        const uploadParams = {
          Bucket: BUCKET_NAME,
          Key: `jobs/${jobId}/${filename}`,
          Body: fileData,
          ContentType: contentType,
        };

        await s3.send(new PutObjectCommand(uploadParams));
        log(`ðŸ“¤ Arquivo enviado para o bucket: ${filename}`);
      } catch (uploadErr) {
        error(`âŒ Erro no upload para o bucket: ${uploadErr.message}`);
      }

      // ðŸ”¥ Remove o arquivo temporÃ¡rio
      try {
        if (fs.existsSync(tempFilePath)) {
          fs.unlinkSync(tempFilePath);
          log(`ðŸ§¹ Arquivo temporÃ¡rio removido: ${tempFilePath}`);
        }
      } catch (unlinkErr) {
        error(`âŒ Falha ao remover arquivo temporÃ¡rio: ${unlinkErr.message}`);
      }
    }
  },
  connection
);

// ðŸ”§ FunÃ§Ã£o de log no banco
async function logJobMetric(clientId, jobId, fileType, status, errorType = null, startedAt = null, endedAt = null) {
  const { data: existing, error: fetchError } = await supabase
    .from("job_metrics")
    .select("id")
    .eq("job_id", jobId)
    .maybeSingle();

  if (fetchError) {
    error("âŒ Erro ao buscar job_metrics:", fetchError);
    return;
  }

  if (existing) {
    const { error: updateError } = await supabase.from("job_metrics").update({
      status,
      error_type: errorType,
      ended_at: endedAt,
    }).eq("job_id", jobId);

    if (updateError) {
      error("âŒ Erro ao atualizar job_metrics:", updateError);
    }
  } else {
    const { error: insertError } = await supabase.from("job_metrics").insert({
      client_id: clientId,
      job_id: jobId,
      file_type: fileType,
      status,
      error_type: errorType,
      started_at: startedAt,
      ended_at: endedAt,
      created_at: new Date().toISOString(),
    });

    if (insertError) {
      error("âŒ Erro ao inserir em job_metrics:", insertError);
    }
  }
}
